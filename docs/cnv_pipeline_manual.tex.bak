\documentclass[11pt]{article}

\usepackage{fullpage,times}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}

\usepackage[sort]{natbib}

\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  allcolors=blue
}

\newcommand{\prog}[1]{\texttt{#1}}

\title{CSI-Cancer Copy Number Analysis Pipeline}
\author{Rish Prabakar}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
This document is intended to serve as a walk through of the copy number
analysis pipeline.

\paragraph{Assumptions:}
\begin{enumerate}
  \item A failarity with the UNIX computing environment.
  \item The ability to compile and install tools and packages.
  \item A familiarity with the commly used bioinformatic file types such
    as fasta, fastq, and sam/bam.
\end{enumerate}

A personal workstation with at least 16GB of memory and 5GB of free disk
space can be used for the analysis of one or at most a few samples.
%
For processing a large number of samples, it is highly recommended that
the analysis be done on a compute cluster such as the
\href{https://carc.usc.edu/}{USC Discovery cluster}. A compute cluster
provied hunderds of nodes that can process files in paraplles, and thus
signigicaly speeding up the analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Copy number analysis}
% CNV pipeline background
This copy number analysis pipline is based on the procedure described in
\citep{baslan2012genome,kendall2014computational}, with modifications to
bin boundares that are designed for 150 bp paired-end read, and with an
addition step of explilitcitly filtereing reads that alignem to
ambiguous or problematic regions of the refrence genome. Briefly, the
human reference genome (hg19) is split into 5000 (20,000 or 50,000) bins
containing an equal number of uniquely mappable locations, and the bin
counts are determined using uniquely mapped reads. Bins with spuriously
high counts (``bad bins,'' typically around centromeric and telomeric
regions) are masked for downstream analysis. This procedure normalizes
bin counts for biases correlated with GC content by fitting a LOWESS
curve to the GC content by bin count, and subtracting the LOWESS
estimate from each bin.  Circular binary segmentation (CBS)
\citep{olshen2004circular}, then identifies breakpoints in the
normalized bin counts.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Tools and packages required}
The following tools are packages are required for copy number analysis:
\begin{enumerate}
\setlength{\itemsep}{0pt}
  \item \href{https://www.bioinformatics.babraham.ac.uk/projects/fastqc/}
    {FastQC}
  \item \href{https://github.com/lh3/bwa}{bwa}
  \item \href{http://www.htslib.org/}{samtools}
  \item \href{https://broadinstitute.github.io/picard/}{Picard tools}
    (requires Java, unfortunately)
  \item Python ($\geq$ 3.0)
  \item Python packages:
    \href{https://pysam.readthedocs.io/en/latest/}{pysam}
  \item R ($\geq 4.0$)
  \item R packages:
    \href{https://cran.r-project.org/web/packages/optparse/index.html}{optparse}
    and \href{https://bioconductor.org/packages/release/bioc/html/DNAcopy.html}
    {DNAcopy}
  \item Optional: \href{https://multiqc.info/}{MultiQC}
\end{enumerate}

All tools are assumed to the located in a directory spefied in
\texttt{\$PATH} and all files are assumed to be in the current working
directory. If they are not, the commands below can be modified to
include the absolute or relative paths to the tool and rquired files.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preparing the reference genome}
\label{index}
The human reference geome (hg19) can be downloaded from the
\href{http://hgdownload.cse.ucsc.edu/goldenpath/hg19/bigZips/chromFa.tar.gz}
{UCSC Genome Browser}. Alternate haplotupes are not used for analysis.
Additionally, the
\href{https://en.wikipedia.org/wiki/Pseudoautosomal\_region}{pseudoautosomal
regions} on chrY is maksed by replacing the bases with Ns. All the
chromosiolmes files can them the merged into one one fasta file.

% build the index
\prog{bwa}, the program used to align reads to the reference geome,
requires the reference genome to be preprocessed once beofoe the first
use.
\begin{verbatim}
$ bwa index hg19.fa
\end{verbatim}

% prebuilt index
The reference genome and the prebuilt index can be downloaded from
\href{}{here}. It is highly recommened to use this pre-built index to
maintain consistanty.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pre-alignment QC}
Prior to any analysis it is crutial to QC the fastq files to detect any
errors in the library preparation or the sequencing process.
\prog{FastQC} provides a set of diagnostic plots on fastq files.
% cmd
\begin{verbatim}
fastqc read_1.fastq.gz read_2.fastq.gz -o fastqc_outdir
\end{verbatim}

% output
The output of \prog{FastQC} is one html file per fastq file contating
some basic statisctis on the fastq file and a set of diagnostic plots.
These html files can be view on any browser. An explanation of these
plots are provided
\href{https://www.bioinformatics.babraham.ac.uk/projects/fastqc/}{here}.
Some importatnt metrics to look for are the read length distribution,
overrepresented sequences such as sequencing adapters, and GC content.

% muliqc
It is generally inconvenitent to view one html file for every fastq
file. The tool \prog{MultiQC} can be used to aggregate all the
inforamtion for all the samples in one html file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Align reads to the reference genome}
The first step in processing the reads is to align them to the reference
genome to detemine their location on the reference genome.
The reads are aligned to the reference genome using \prog{bwa}
\citep{li2013aligning}.
The input to \prog{bwa} are a pair of fastq files and the pre-built
reference index (as descriobed in section \ref{index}).

The input reads ususally contain primer sequences from the whole genome
amplification or adapter sequences from the Illumina library
proparation process at the ends. \prog{bwa} perfoms a local alignment on the
reads and soft clips any of these unwanted technical bases that would
not align to the reference genome. Therefore is not required to
explicitly trim the adapter squences prior to processing them with
\prog{bwa}.

% cmd
\begin{verbatim}
$ bwa mem -t {threads} {path_to_bwa_index} \
    read_1.fastq.gz read_2.fastq.gz \
    1> sample.sam 2> sample_bwa_log.txt
\end{verbatim}

% output
The output of \prog{bwa} is a sam file. The first few lines of a sam
file contains a header that starts with a \texttt{@}. The subsequenct
lines contains one entry for each read, and thus two entries for a read
pair (but could contain more than two entries when a read is split and
alined to more than one location on the reference).
%
Each entry is a tab demimated, and the first five columns privide the
most useful information in the context of copy number profiling: (1) The
read name. (2) A decimal representation of a bitwise combination of 12
bits, where each bit represents a properyty of the alginment. (3) The
chromosome to whcih the read aligns to. (4) The position on the
chromosome to which the read aligns to. (5) Mapping quality of the read
which is calcuated as $-10 \log_{10} \mathrm{Pr(mapping\ postion\ is
\ wrong)}$.
%
A detailed specification of a sam file format can be found
\href{https://samtools.github.io/hts-specs/SAMv1.pdf}{here}.

% convert to bam
sam files are convient to view on text editor. However, these files
consume a lot of disk space since they are not compressed. bam files are
the compressed version of sam files, and the formats can be conveted
with \prog{samtools} (the sam file can then be deleted).
\begin{verbatim}
$ samtools view -@ {threads} -b -o sample.bam sample.sam
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Remove PCR duplicates}
Several steps in going from $\sim$6pg of DNA in a cell to the $~\sim$100ng
required for Illumina library prepation involes PCR amplification, which
could lead to capturing two identical DNA fragments in the sequecning prcess.
Since these reads are identical, the presence of more than one reads or
indentical fragments does not proivde any additional inforamtion, but
could lead to a bias in the downstream analysis.

% A good library
A good library that has a high complexity contains very few duplicated
reads. A library that contains a high fraction of PCR duplicates ($>30-40\%$)
could indicative of low DNA content in the cell or high genome drop out,
and should de treasted with caution.

% How PCR duplicates are removed
PCR duplicates are removed based on the assumption that two read pairs
that aling to exactly the same location on the reference genome is more
likely do it it being a PCR duplicate than it actally being two differnt
molecules. This is reasonable assumption for whole genome sequcing at a
low coverage sequcning especially for a single cell. (However, this
method of removing PCR duplicates cannot be used for high coverage or
targeted sequening.) Multiple read paris that align to the referen at
the same 5' location of both the forward and the reverse reads. A
graphical representaiton of a PCR duplicate can be found
\href{https://www.htslib.org/algorithms/duplicate.html}{here}.

% cmd
PCR duplicates are removed with \prog{samtools} with a set of four
commands. The first command name sorts the bam file so that each all the
aligments that belong to a read pair are adjacent in the bam file.
\begin{verbatim}
$ samtools collate -@ {threads} -o sample_collate.bam sample.bam
\end{verbatim}
%
\prog{bwa} and other mapping tools typically do not provie the correct
infomation about the insert size for the read piars. \prog{samtools
fixmate} fixes these.
\begin{verbatim}
$ samtools fixmate -@ {threads} -m sample_collate.bam \
    sample_fixmate.bam
\end{verbatim}
%
The bam file is them sorted based on the genome coordinates to
facilatiate removing PCR duplicates.
\begin{verbatim}
$ samtools sort -@ {threads} -o sample_sorted.bam sample_fixmate.bam
\end{verbatim}
%
Finally, the PCR dupicates are removed and only the best alignment for
each is retained.
\begin{verbatim}
$ samtools markdup -@ {threads} -r sample_sorted.bam sample_rmdup.bam
\end{verbatim}

% output
The final output of these steps is a bam file in which all the duplicate
reads are discarded, and thus contains fewer reads than the input bam
file.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Remove low quality and ambiguously mapped reads}
Reads read that aligns to several different locations on the reference
genome recieves a low mapping quality score (in the first column of a
sam entry). Since a uniqe location for these aligmemnts cannot be
determined they do not provide any useful information for copy number
profiling and they can be discareded. Further, for reads that get split
and align to multiple locations, only the best alinment is retained. The
alignments are filetered with \prog{samtools}:
% cmd
\begin{verbatim}
$ samtools view -@ {threads} -q 30 -F 0x800 -o sample_unique.bam \
    sample_rmdup.bam
\end{verbatim}
% output
The output is a bam file that retains only the uniqe alignments.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Remove mates}
Since a sam file contains two entries for each read pair, one of these
needs to be removed prior to copy number profiling. Not doing so would
lead to double counting each alignment. \prog{samtools} is used to
remove the alignmets correspoing to the second read of the read pair.
% cmd
\begin{verbatim}
$ samtools view -@ {threads} -f 0x40 -h -o sample_fwd.bam \
    sample_unique.bam
\end{verbatim}
% output
The output is a bam file that retains only the alignments that belong to
the first read of the read pair.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Post alignment QC}
It is highly recommended to check the number of alignments that are
discarded after each step of the above filetering process. The number of
alignments, the number of read pairs, etc in a sam file can be deterined
using the command:
\begin{verbatim}
$ samtools flagstat {bam_file.bam}
\end{verbatim}
Of note, in the output of \prog{samtools flagstat}, the fraction of
aligned reads are calucated based on the number of alignmnets in the sam
fail (and not based on the number of reads in the fastq files for the
sample).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Insert size distribution}
As an additional QC, it is important to check the insert size
distribution on the aligned reads. A good sequencing library should have
a mojority of reads with an insert size greater than 100 bp. Samples
with a loarger fraction of inserts less than 50bp should be treated with
causion.
\begin{verbatim}
$ java -jar picard CollectInsertSizeMetrics I=sample_unique.bam
  O=sample_insert_sz.txt H=sample_insert_sz.pdf
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generate bin counts}
At this statge, the sam file is ready to be used for copy number
profiling.  The next step is to detemine the number of reads that align
to each predteremined bins on the reference genome.
% bin boundaries
The bin boundaries were determined so that the number of uniqely
mappanle regions in the bins are approximately the same across all the
bins (and so the absolte width of each bin varies, with larger bins in
regions of the genome that contain repetitative sequences and smaller in
regions that mostly contain uniue sequencies).

% problematic regions
Further, there certain regions of the genome that are known to be
``problematic'' that have an unusually high number of unique reads
aligning to it \citep{amemiya2019encode}. In addition to the ambiguously
mapping regions of the genome, these problematic regions are excluded as
well when determining the bin boundaries.

%
\prog{getBinCounts.py} takes as input a bed file containg the genomic
cooridates of the bin boundaries, a bed file containing the geomic
cooridnates of all the ambiguously mapping regiosn and the problematic
regions, and the sam file containing only the forars reads. For each
aligmnet in the sam file, it is discarded if it is aligned to ambigiuos
or problematic regions, otherwise the count of the bin that it beongs to
is incremented by one.
% cmd
\begin{verbatim}
$ getBinCounts.py -i sample_fwd.bam -b hg19_5k_gz_enc_bins.bed \
    -d hg19_150bp_dz_enc.bed -o sample_5k_counts.bed \
    -v > sample_5k_counts_stats.txt
\end{verbatim}

% data
\prog{getBinCounts.py} is located in the
\href{https://github.com/CSI-Cancer/CNVPipeline/tree/master/scripts}{scripts}
directoy and the bed files are located in the
\href{https://github.com/CSI-Cancer/CNVPipeline/tree/master/data}{data}
directory in the GitHub repositiory. The above command determines the
counts for 5,000 bin. For genrateting profiles at other resolutions, use
the appropriate bed file.

% output
The output is a bed file that contains the genominc coordinates of the
bin boudaraies with an added fourth colum containing the counts for
that bin. The stats file provides some basic statistics on the number of
input alinment, the number of filetred alignmeint, and the number of
alginmed that is used for copy number profiling.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generate copy number profiles}
The final step is to conver the bin counts into bin ratios and segmented
copy number progiles. The counts are normalized to account for the
differences in the number of reads sequenced between samples, lowess
smoothed to account for the differences in GC content between bins, and
segmented using circular binary segmentation.

% input
\prog{cnvProfile.R} takes as input the bin counts, a bed file containing
the GC content of each bin, and an option bed file contatining the ``bad
bins.''
% cmd
\begin{verbatim}
$ cnvProfile.R -b sample_5k_counts.bed -g hg19_5k_gz_enc_gc.bed \
    -e hg19_5k_gz_enc_badbind.bed -o {output_dir} -n {sample_name} -v
\end{verbatim}

% output
The outout is a pdf file containing a copy number profile, and two tab
separated files containg all the infomation ralted to the copy number
profile such as the bin ratios and the segmeted values. One of these
file contains the same number of rows as the number of bins used, and
the other file is shorter version that contains one row for each copy
number segment. The these files can be used as an input to any downstram
applications such as genrateing copy number heatmaps.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Detmining the bin boundaries}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plainnat}
\bibliography{cnv_pipeline_manual}


\end{document}

